{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec11d5fe-ca07-4c42-b36b-59c1014c41d6",
   "metadata": {},
   "source": [
    "A rough copy of https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da6c8045-ddb0-4b6c-8d2d-b748a2403dfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from helpers import get_gpu\n",
    "device = get_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f09ac9bf-59ad-4604-b522-30c6a2aff9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = Path(\"..\").resolve(strict=True) / \"data\"\n",
    "data = pd.read_csv(data_dir / \"bbc-text.csv\")\n",
    "labels = {\"business\": 0, \"entertainment\": 1, \"sport\": 2, \"tech\": 3, \"politics\": 4}\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b4c1db2-f642-4dae-8a57-7e598a5ba86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.labels = [labels[category] for category in data[\"category\"]]\n",
    "        self.texts = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            for text in data[\"text\"]\n",
    "        ]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], np.array(self.labels[idx])\n",
    "\n",
    "    \n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-cased\")\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(768, 5)\n",
    "    \n",
    "    def __call__(self, input_ids, mask):\n",
    "        _, output = self.bert(input_ids=input_ids, attention_mask=mask, return_dict=False)\n",
    "        output = self.fc(self.dropout(output)).relu()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96fd0109-4d6a-41f9-a8cd-f38ef86900e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "train_df, valid_df, test_df = np.split(\n",
    "    data.sample(frac=1, random_state=1337), [int(0.8*len(data)), int(0.9*len(data))]\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(Dataset(train_df), batch_size=2, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(Dataset(valid_df), batch_size=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = BERTClassifier().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "844dab33-fb9e-4ede-922e-879042ca16e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 890/890 [04:37<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | train loss 0.750 | train accuracy 0.345 | valid loss 0.567 | valid accuracy 0.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 890/890 [04:44<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 | train loss 0.387 | train accuracy 0.778 | valid loss 0.314 | valid accuracy 0.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 890/890 [04:41<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 | train loss 0.176 | train accuracy 0.946 | valid loss 0.113 | valid accuracy 0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 890/890 [04:42<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 | train loss 0.074 | train accuracy 0.990 | valid loss 0.062 | valid accuracy 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 890/890 [04:44<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 | train loss 0.042 | train accuracy 0.996 | valid loss 0.040 | valid accuracy 0.986\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    total_train_loss = 0\n",
    "    total_train_correct = 0\n",
    "    for train_input, train_label in tqdm(train_dataloader):\n",
    "        mask = train_input[\"attention_mask\"].to(device)\n",
    "        input_id = train_input[\"input_ids\"].squeeze(1).to(device)\n",
    "        output = model(input_id, mask)\n",
    "        train_label = train_label.to(device)\n",
    "        loss = criterion(output, train_label.long())\n",
    "        total_train_loss += loss.item()\n",
    "        total_train_correct += (output.argmax(dim=1) == train_label).sum().item()\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    total_valid_loss = 0\n",
    "    total_valid_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for valid_input, valid_label in valid_dataloader:\n",
    "            mask = valid_input[\"attention_mask\"].to(device)\n",
    "            input_ids = valid_input[\"input_ids\"].squeeze(1).to(device)\n",
    "            output = model(input_ids, mask)\n",
    "            valid_label = valid_label.to(device)\n",
    "            loss = criterion(output, valid_label.long())\n",
    "            total_valid_loss += loss.item()\n",
    "            total_valid_correct += (output.argmax(dim=1) == valid_label).sum().item()\n",
    "    print(\n",
    "        f\"epoch {epoch+1} | \"\n",
    "        f\"train loss {total_train_loss / len(train_df):.3f} | \"\n",
    "        f\"train accuracy {total_train_correct / len(train_df):.3f} | \"\n",
    "        f\"valid loss {total_valid_loss / len(valid_df):.3f} | \"\n",
    "        f\"valid accuracy {total_valid_correct / len(valid_df):.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ffefd81-dea0-42d0-b64c-3e34dd0dcf2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.987\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(Dataset(test_df), batch_size=2)\n",
    "total_test_correct = 0\n",
    "with torch.no_grad():\n",
    "    for test_input, test_label in test_dataloader:\n",
    "        mask = test_input[\"attention_mask\"].to(device)\n",
    "        input_ids = test_input[\"input_ids\"].squeeze(1).to(device)\n",
    "        output = model(input_ids, mask)\n",
    "        test_label = test_label.to(device)\n",
    "        total_test_correct += (output.argmax(dim=1) == test_label).sum().item()\n",
    "print(f\"test accuracy {total_test_correct / len(test_df):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaad836-35c8-451d-8c43-d6e6ebc0ed09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
