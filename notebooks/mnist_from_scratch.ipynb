{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST from Scratch\n",
    "\n",
    "Can I train a model to recognize handwritten digits using numpy?\n",
    "\n",
    "1. Load the MNIST dataset from the web and store as NumPy arrays\n",
    "2. Train a simple model to solve MNIST using PyTorch\n",
    "3. Do the same with NumPy by implementing various ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "from torch import nn, Tensor, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_dir: Path, file_name: str) -> np.ndarray:\n",
    "    # can be done with numpy.genfromtxt(), but is much slower\n",
    "    dataset = pd.read_csv(data_dir / file_name)\n",
    "    x = dataset.drop(\"label\", axis=1).to_numpy() / 255.0\n",
    "    y = dataset[\"label\"].to_numpy()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_path = Path(\".\").resolve(strict=True).parent / \"data\" / \"mnist\"\n",
    "x_train, y_train = load_dataset(mnist_path, \"mnist_train.csv\")\n",
    "x_test, y_test = load_dataset(mnist_path, \"mnist_test.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(784, 256, bias=False)\n",
    "        self.layer2 = nn.Linear(256, 64, bias=False)\n",
    "        self.layer3 = nn.Linear(64, 10, bias=False)\n",
    "        self.act = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.act(self.layer1(x))\n",
    "        x = self.act(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 500\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = NeuralNet()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 499 loss 0.16: 100%|██████████| 500/500 [00:02<00:00, 189.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for i in (t := trange(iterations)):\n",
    "    sample = np.random.randint(0, len(x_train), size=batch_size)\n",
    "    out = model(Tensor(x_train[sample]))\n",
    "    loss = loss_func(out, Tensor(y_train[sample]).long())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.zero_grad()\n",
    "    t.set_description(f\"Iteration {i} loss {loss.item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9373999834060669"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy\n",
    "pred = model(Tensor(x_test)).argmax(dim=1)\n",
    "accuracy = (pred == Tensor(y_test)).float().mean().item()\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = model.layer1.weight.detach().numpy().astype(np.float64)\n",
    "w2 = model.layer2.weight.detach().numpy().astype(np.float64)\n",
    "w3 = model.layer3.weight.detach().numpy().astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x: np.ndarray) -> np.ndarray:\n",
    "    x = np.maximum(x @ w1.T, 0)\n",
    "    x = np.maximum(x @ w2.T, 0)\n",
    "    x = x @ w3.T\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9374"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = forward(x_test).argmax(axis=1)\n",
    "accuracy = (pred == y_test).mean()\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now solve with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_init(m, h):\n",
    "    weights = np.random.uniform(low=-1., high=1., size=(m, h)) / np.sqrt(m * h)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = layer_init(256, 784)\n",
    "w2 = layer_init(64, 256)\n",
    "w3 = layer_init(10, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saved_forward(x0: np.ndarray) -> tuple[np.ndarray]:\n",
    "    x1 = x0 @ w1.T  # 64 * 256\n",
    "    x2 = np.maximum(x1, 0)  # 64 * 256\n",
    "    x3 = x2 @ w2.T  # 64 * 64\n",
    "    x4 = np.maximum(x3, 0)  # 64 x 64\n",
    "    x5 = x4 @ w3.T  # 64 x 10\n",
    "    return x5, x4, x3, x2, x1, x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(pred: np.ndarray, labels: np.ndarray) -> tuple[float, np.ndarray]:\n",
    "    # y is the one-hot enconding of labels\n",
    "    actual = np.zeros((labels.size, 10))\n",
    "    actual[np.arange(labels.size), labels] = 1\n",
    "    # do total squared error for now\n",
    "    error = pred - actual\n",
    "    loss = np.sum((pred - actual) ** 2)\n",
    "    return loss, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(error: np.ndarray, xs: tuple[np.ndarray]) -> tuple[np.ndarray]:\n",
    "    x5, x4, x3, x2, x1, x0 = xs  # 64 * 10, 64 * 64, 64 * 64, 64 * 256, 64 * 256, 64 * 784\n",
    "    dx5 = np.ones_like(x5) * error * 2  # 64 * 10\n",
    "    dw3 = (x4.T @ dx5).T   # 10 * 64\n",
    "    dx4 = dx5 @ w3  # 64 * 64\n",
    "    dx3 = (x4 > 0).astype(np.float64) * dx4  # 64 * 64\n",
    "    dw2 = (x2.T @ dx3).T  # 64 * 256\n",
    "    dx2 = dx3 @ w2  # 64 * 256\n",
    "    dx1 = (x2 > 0).astype(np.float64) * dx2  # 64 x 256\n",
    "    dw1 = (x0.T @ dx1).T  # 256 x 784\n",
    "    assert dw3.shape == w3.shape\n",
    "    assert dw2.shape == w2.shape\n",
    "    assert dw1.shape == w1.shape\n",
    "    return dw3, dw2, dw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(ws: tuple[np.ndarray], dws: tuple[np.ndarray], lr: float = 0.001) -> tuple[np.ndarray]:\n",
    "    for wi, dwi in zip(ws, dws):\n",
    "        wi -= lr * dwi\n",
    "    return ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 1999 loss 13.45: 100%|██████████| 2000/2000 [00:10<00:00, 184.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in (t := trange(2000)):\n",
    "    sample = np.random.randint(0, len(x_train), size=batch_size)\n",
    "    xs = saved_forward(x_train[sample])\n",
    "    loss, error = mse(xs[0], y_train[sample].astype(int))\n",
    "    dws = backward(error, xs)\n",
    "    update_weights((w3, w2, w1), dws)\n",
    "    t.set_description(f\"Iteration {i} loss {loss.item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.942"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = forward(x_test).argmax(axis=1)\n",
    "accuracy = (pred == y_test).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
